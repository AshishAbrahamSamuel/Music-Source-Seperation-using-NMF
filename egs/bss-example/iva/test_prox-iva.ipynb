{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_prox-iva.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyOc59nGGfkOYUCPVbIsq/fK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"G92TErtpQfTp"},"source":["# Multichannel audio source separation by ProxIVA"]},{"cell_type":"code","metadata":{"id":"0O9jzOgVmq7X"},"source":["%%shell\n","git clone https://github.com/tky823/audio_source_separation.git"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"v4Dget11m1Ks"},"source":["%cd \"/content/audio_source_separation/egs/bss-example/iva\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fKmmzwP1m15I"},"source":["import sys\n","sys.path.append(\"../../../src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i7Bob6ZUm12j"},"source":["import numpy as np\n","import scipy.signal as ss\n","import soundfile as sf\n","import IPython.display as ipd\n","import matplotlib.pyplot as plt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GKcqqsn7m1z_"},"source":["from bss.iva import ProxLaplaceIVA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gx4qtf3RoGkc"},"source":["plt.rcParams['figure.dpi'] = 200"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RmKxO9ylQdE1"},"source":["## 1 Music source separation"]},{"cell_type":"markdown","metadata":{"id":"a7ODtH-aQkF0"},"source":["### Data preparation for music source separation\n","We already created multichannel mixtures using the impulse responses of [Multi-Channel Impulse Response Database](https://www.iks.rwth-aachen.de/en/research/tools-downloads/databases/multi-channel-impulse-response-database/).\n","You can find the original sources (piano & violin) and its mixture in `audio_source_separation/dataset/sample-song/`."]},{"cell_type":"markdown","metadata":{"id":"8tDx3FOkQmO9"},"source":["### Target sources"]},{"cell_type":"code","metadata":{"id":"x7fjP5UzoGgf"},"source":["source_piano, sr = sf.read(\"../../../dataset/sample-song/sample-2_piano_16000.wav\")\n","source_violin, sr = sf.read(\"../../../dataset/sample-song/sample-2_violin_16000.wav\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DL-f1nzeoGd1"},"source":["display(ipd.Audio(source_piano, rate=sr))\n","display(ipd.Audio(source_violin, rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bSiFYrA_oGbO"},"source":["s = np.vstack([source_piano, source_violin])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cnlsFyMwQq1V"},"source":["### Mixture"]},{"cell_type":"code","metadata":{"id":"c8xMedj6oGX5"},"source":["mixture, sr = sf.read(\"../../../dataset/sample-song/sample-2_mixture_16000.wav\")\n","x = mixture.T\n","n_channels, T = x.shape\n","n_sources = n_channels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oxFCpUmUoGVd"},"source":["for idx in range(n_channels):\n","    display(ipd.Audio(x[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ETapYTcRQyap"},"source":["Configuration of STFT\n","- The reverberation time is $T_{60}=160$ [ms] in the impulse response.\n","- The window length is $4096$ samples (= $256$ [ms]) because of the assumption of rank-1 constraint.\n","- The hop length is the half of the window length, i.e. $2048$ samples (= $128$ [ms]) ."]},{"cell_type":"code","metadata":{"id":"SAB3SC1voPC_"},"source":["fft_size, hop_size = 4096, 2048"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mIMi42irQ2DP"},"source":["### Exection of IVA"]},{"cell_type":"code","metadata":{"id":"-l1b51uqoPAk"},"source":["_, _, X = ss.stft(x, nperseg=fft_size, noverlap=fft_size-hop_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YGCn-vlmoO-I"},"source":["np.random.seed(111)\n","iva = ProxLaplaceIVA(regularizer=1, step=1.75)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VHILM0Zrozlm"},"source":["print(iva)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_QJ1biOUdQ_H"},"source":["Y = iva(X, iteration=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XWp5ioTlopXD"},"source":["_, y = ss.istft(Y, nperseg=fft_size, noverlap=fft_size-hop_size)\n","y = y[:, :T]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WeDWv9NuQ4xH"},"source":["### Separated sources"]},{"cell_type":"code","metadata":{"id":"6tZTwqo-o2S7"},"source":["for idx in range(n_sources):\n","    display(ipd.Audio(y[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"58HLzNxQo2MP"},"source":["plt.figure()\n","plt.plot(iva.loss, color='black')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IjYi2QU8Q74u"},"source":["## 2 Speech separation"]},{"cell_type":"markdown","metadata":{"id":"xDFtBtE3Q-U9"},"source":["### 2.1 Data preparation for speech separation\n","Create multichannel mixtures using the audios of [CMU ARCTIC database](http://www.festvox.org/cmu_arctic/) and impulse responses of [Multi-Channel Impulse Response Database](https://www.iks.rwth-aachen.de/en/research/tools-downloads/databases/multi-channel-impulse-response-database/)."]},{"cell_type":"code","metadata":{"id":"f-53cXUOo2GH"},"source":["%%shell\n",". ./prepare.sh"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fzYexOpdRCaY"},"source":["Configuration of STFT\n","- The reverberation time is $T_{60}=160$ [ms] in the impulse response.\n","- The window length is $4096$ samples (= $256$ [ms]) because of the assumption of rank-1 constraint.\n","- The hop length is the half of the window length, i.e. $2048$ samples (= $128$ [ms]) ."]},{"cell_type":"code","metadata":{"id":"jZTQ6vdFRGCj"},"source":["fft_size, hop_size = 4096, 2048"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1ffQJ_-ERfVj"},"source":["### 2.2 2 speakers"]},{"cell_type":"code","metadata":{"id":"_1tVHr0gRdku"},"source":["aew_mic3, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic3.wav\")\n","axb_mic3, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic3.wav\")\n","x_mic3 = aew_mic3 + axb_mic3\n","\n","aew_mic4, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic4.wav\")\n","axb_mic4, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic4.wav\")\n","x_mic4 = aew_mic4 + axb_mic4\n","\n","x = np.vstack([x_mic3, x_mic4])\n","n_channels, T = x.shape\n","n_sources = n_channels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-81fDiuuRh5Y"},"source":["#### Target sources after convolution of impulse response"]},{"cell_type":"code","metadata":{"id":"spoBW9GeRiMV"},"source":["display(ipd.Audio(aew_mic3, rate=sr))\n","display(ipd.Audio(axb_mic3, rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dvarvJTXRs_M"},"source":["#### Mixture"]},{"cell_type":"code","metadata":{"id":"DmVlL1ETRmpx"},"source":["for idx in range(n_channels):\n","    display(ipd.Audio(x[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hEMaQ3fqR4tk"},"source":["#### Execution of IVA"]},{"cell_type":"code","metadata":{"id":"vSZv80QlR3Sp"},"source":["_, _, X = ss.stft(x, nperseg=fft_size, noverlap=fft_size-hop_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRIT3xW1R3Pz"},"source":["np.random.seed(111)\n","iva = ProxLaplaceIVA(regularizer=1, step=1.75)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VWwrhvD1o0jG"},"source":["print(iva)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zy96IWxfR3NU"},"source":["Y = iva(X, iteration=500)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FtTFKhPfR8_A"},"source":["_, y = ss.istft(Y, nperseg=fft_size, noverlap=fft_size-hop_size)\n","y = y[:,:T]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RoumnJj2SBd9"},"source":["#### Separated sources"]},{"cell_type":"code","metadata":{"id":"rjROGTdxR87r"},"source":["for idx in range(n_sources):\n","    display(ipd.Audio(y[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fzCG7FkDSLQw"},"source":["plt.figure()\n","plt.plot(iva.loss, color='black')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UkGWcjWmScDW"},"source":["### 2.3 3 speakers"]},{"cell_type":"code","metadata":{"id":"HOip8nsmSaV6"},"source":["aew_mic2, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic2.wav\")\n","axb_mic2, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic2.wav\")\n","bdl_mic2, sr = sf.read(\"./data/cmu_us_bdl_arctic/trimmed/convolved-16000_deg330-mic2.wav\")\n","x_mic2 = aew_mic2 + axb_mic2 + bdl_mic2\n","\n","aew_mic4, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic4.wav\")\n","axb_mic4, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic4.wav\")\n","bdl_mic4, sr = sf.read(\"./data/cmu_us_bdl_arctic/trimmed/convolved-16000_deg330-mic4.wav\")\n","x_mic4 = aew_mic4 + axb_mic4 + bdl_mic4\n","\n","aew_mic5, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic5.wav\")\n","axb_mic5, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic5.wav\")\n","bdl_mic5, sr = sf.read(\"./data/cmu_us_bdl_arctic/trimmed/convolved-16000_deg330-mic5.wav\")\n","x_mic5 = aew_mic5 + axb_mic5 + bdl_mic5\n","\n","x = np.vstack([x_mic2, x_mic4, x_mic5])\n","n_channels, T = x.shape\n","n_sources = n_channels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"U42QRyx0S3Su"},"source":["#### Target sources after convolution of impulse response"]},{"cell_type":"code","metadata":{"id":"meaSDFd3R84X"},"source":["display(ipd.Audio(aew_mic2, rate=sr))\n","display(ipd.Audio(axb_mic2, rate=sr))\n","display(ipd.Audio(bdl_mic2, rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MCiRfwj_U6k2"},"source":["#### Mixture"]},{"cell_type":"code","metadata":{"id":"_fWLJyTUS1xH"},"source":["for idx in range(n_channels):\n","    display(ipd.Audio(x[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7bUgC_L3TIDK"},"source":["#### Execution of IVA"]},{"cell_type":"code","metadata":{"id":"ni4zWwNIS1t8"},"source":["_, _, X = ss.stft(x, nperseg=fft_size, noverlap=fft_size-hop_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SAtz4q_7TSVa"},"source":["np.random.seed(111)\n","iva = ProxLaplaceIVA(regularizer=1, step=1.75)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tx6NrXIPo13I"},"source":["print(iva)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t7mokIwETTsK"},"source":["Y = iva(X, iteration=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ikuoKouMTU24"},"source":["_, y = ss.istft(Y, nperseg=fft_size, noverlap=fft_size-hop_size)\n","y = y[:,:T]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WaKR0Ap-VAyu"},"source":["#### Separated sources"]},{"cell_type":"code","metadata":{"id":"C3tDW4ZfTWPM"},"source":["for idx in range(n_sources):\n","    display(ipd.Audio(y[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZFgQOpYmTk2N"},"source":["plt.figure()\n","plt.plot(iva.loss, color='black')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3m3Dt9noblDF"},"source":["## 3 Comparison between AuxIVA and ProxIVA"]},{"cell_type":"code","metadata":{"id":"oKHICYFsTsaG"},"source":["%%shell\n","pip install mir_eval"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mbYGIf9CT-I5"},"source":["from mir_eval.separation import bss_eval_sources"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HxlVlCAwT9IR"},"source":["from bss.iva import AuxLaplaceIVA\n","from algorithm.projection_back import projection_back"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GB1-t0bUTodr"},"source":["aew_mic3, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic3.wav\")\n","axb_mic3, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic3.wav\")\n","x_mic3 = aew_mic3 + axb_mic3\n","\n","aew_mic4, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic4.wav\")\n","axb_mic4, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic4.wav\")\n","x_mic4 = aew_mic4 + axb_mic4\n","\n","x = np.vstack([x_mic3, x_mic4])\n","n_channels, T = x.shape\n","n_sources = n_channels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"P4ISrPayTqnj"},"source":["s = np.vstack([aew_mic3, axb_mic3])\n","_, _, X = ss.stft(x, nperseg=fft_size, noverlap=fft_size-hop_size)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3JIMV31ZT_5O"},"source":["def record_sdri(model):\n","    reference_id = model.reference_id\n","    s = model.target # Time domain\n","    X, Y = model.input, model.estimation # Time-frequency domain\n","    n_sources, T = s.shape\n","\n","    scale = projection_back(Y, reference=X[reference_id])\n","    Y = Y * scale[...,np.newaxis] # (n_sources, n_bins, n_frames)\n","    _, y = ss.istft(Y, nperseg=fft_size, noverlap=fft_size-hop_size)\n","    y = y[:,:T]\n","\n","    if hasattr(model, 'sdr_input'):\n","        sdr_input = model.sdr_input\n","    else:\n","        _, x = ss.istft(X, nperseg=fft_size, noverlap=fft_size-hop_size)\n","        x = x[reference_id,:T]\n","        x = np.tile(x, reps=(n_sources, 1))\n","        sdr_input, _, _, _ = bss_eval_sources(s, estimated_sources=x)\n","        model.sdr_input = sdr_input\n","\n","    sdr_estimated, _, _, _ = bss_eval_sources(s, estimated_sources=y)\n","    sdri = sdr_estimated - sdr_input\n","    \n","    model.sdri.append(sdri.mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BY28ru6cUBRR"},"source":["np.random.seed(111)\n","aux_iva = AuxLaplaceIVA(callback=record_sdri)\n","Y = aux_iva(X, iteration=50, target=s, sdri=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"aeYmuUuJUCxL"},"source":["np.random.seed(111)\n","prox_iva = ProxLaplaceIVA(regularizer=1, step=1.75)\n","Y = prox_iva(X, iteration=50, target=s, sdri=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qy5lgKHCUEJY"},"source":["plt.figure()\n","plt.plot(aux_iva.loss, color='black', label='AuxIVA')\n","plt.plot(prox_iva.loss, color='mediumblue', label='ProxIVA')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlVutmQWc38t"},"source":[""],"execution_count":null,"outputs":[]}]}