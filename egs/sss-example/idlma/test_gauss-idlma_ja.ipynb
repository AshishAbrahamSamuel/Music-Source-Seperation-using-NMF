{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_gauss-idlma_ja.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"authorship_tag":"ABX9TyNP/ti86t4WnDN8Lj6BmJ8a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"BdVYWGttaIzo"},"source":["# Gauss-IDLMAによる多チャネル音源分離\n","**注意**: このサンプルではDNNを学習していないため，分離の品質が低い．"]},{"cell_type":"code","metadata":{"id":"1WqGd8JWXeny"},"source":["%%shell\n","git clone https://github.com/tky823/audio_source_separation.git\n","pip install soundfile"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QwNLvyj-XjES"},"source":["%cd \"/content/audio_source_separation/egs/sss-example/idlma\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3QFsqE1MXnBu"},"source":["## データの準備\n","[CMU ARCTICデータベース](http://www.festvox.org/cmu_arctic/)の音声，および[Multi-Channel Impulse Response Database](https://www.iks.rwth-aachen.de/en/research/tools-downloads/databases/multi-channel-impulse-response-database/)のインパルス応答を用いて，多チャネルの混合音をシミュレーションする．"]},{"cell_type":"code","metadata":{"id":"bTwJ1VTnXkWU"},"source":["%%shell\n",". ./prepare.sh"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGioC6WJXlq4"},"source":["import sys\n","sys.path.append(\"../../../src\")\n","sys.path.append(\"./src\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0_-iEfoTXpvW"},"source":["import numpy as np\n","import scipy.signal as ss\n","import soundfile as sf\n","import IPython.display as ipd\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xMrnHVZyXrJN"},"source":["from sss.idlma import GaussIDLMA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ark-o6uxXsVI"},"source":["plt.rcParams['figure.dpi'] = 200"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VQSeQaVvXv62"},"source":["窓長などについて\n","- $T_{60}=160$ [ms]の残響のインパルス応答を使用する．\n","- 空間がランク$1$である仮定から，フーリエ変換の窓長は，$4096$サンプル（$=256$ [ms]）としている．\n","- シフト長は，窓長の半分の$2048$サンプルとしている"]},{"cell_type":"code","metadata":{"id":"xMvqdUQJXtho"},"source":["fft_size, hop_size = 4096, 2048"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"b6UEbhqEXzU-"},"source":["## DNN\n","`MLP` は`(batch_size, n_bins)`のサイズの入力から単一の音源を推定する．\n","\n","`MLPforEstimation`は`(n_sources, n_bins, n_frames)`のサイズの入力から単一の音源を推定する．"]},{"cell_type":"code","metadata":{"id":"HfEHVQeBXzLu"},"source":["class MLP(nn.Module):\n","    def __init__(self, n_bins, hidden_channels=1024, num_layers=5):\n","        super().__init__()\n","\n","        net = []\n","        for n in range(num_layers):\n","            if n == 0:\n","                net.append(nn.Linear(n_bins, hidden_channels))\n","            elif n == num_layers - 1:\n","                net.append(nn.Linear(hidden_channels, n_bins))\n","            else:\n","                net.append(nn.Linear(hidden_channels, hidden_channels))\n","            net.append(nn.ReLU())\n","        self.net = nn.Sequential(*net)\n","\n","\n","    def forward(self, input):\n","        \"\"\"\n","        Args:\n","            input (batch_size, n_bins)\n","        Returns:\n","            output (batch_size, n_bins)\n","        \"\"\"\n","        output = self.net(input)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1CHKJLlMXxix"},"source":["class MLPforEstimation(nn.Module):\n","    def __init__(self, n_bins, hidden_channels=2049, num_layers=5, n_sources=None):\n","        super().__init__()\n","        if n_sources is None:\n","            raise ValueError(\"Specify number of sources.\")\n","        \n","        net = []\n","        for n in range(n_sources):\n","            net.append(MLP(n_bins, hidden_channels=hidden_channels, num_layers=num_layers))\n","        \n","        self.net = torch.nn.ModuleList(net)\n","    \n","    def forward(self, input):\n","        output = []\n","        for n, x in enumerate(input):\n","            x = x.permute(1, 0)\n","            x = self.net[n](x)\n","            x = x.permute(1, 0).unsqueeze(dim=0)\n","            output.append(x)\n","        \n","        output = torch.cat(output, dim=0)\n","\n","        return output"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VzX679bTX30q"},"source":["このサンプルでは学習していないDNNを用いているが，実際にはDNNを事前に学習させる必要がある．"]},{"cell_type":"markdown","metadata":{"id":"FfhcQmgJX5qH"},"source":["## 2音源分離"]},{"cell_type":"code","metadata":{"id":"Zln9bLnBX2MU"},"source":["aew_mic3, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic3.wav\")\n","axb_mic3, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic3.wav\")\n","x_mic3 = aew_mic3 + axb_mic3\n","\n","aew_mic4, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic4.wav\")\n","axb_mic4, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic4.wav\")\n","x_mic4 = aew_mic4 + axb_mic4\n","\n","x = np.vstack([x_mic3, x_mic4])\n","n_sources, T = x.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xNE2okuTX863"},"source":["### インパルス応答畳み込み後の音"]},{"cell_type":"code","metadata":{"id":"nTKxeG9sX7aT"},"source":["display(ipd.Audio(aew_mic3, rate=sr))\n","display(ipd.Audio(axb_mic3, rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nOVHYxu9YAJV"},"source":["### 混合音"]},{"cell_type":"code","metadata":{"id":"JpvrA21yX-lg"},"source":["for idx in range(2):\n","    display(ipd.Audio(x[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yOq2JL4TYA1N"},"source":["_, _, X = ss.stft(x, nperseg=fft_size, noverlap=fft_size-hop_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_y4qQx-aYDvQ"},"source":["### ILRMAの実行"]},{"cell_type":"code","metadata":{"id":"RIrBKdpTYCOn"},"source":["torch.manual_seed(111)\n","dnn = MLPforEstimation(n_bins=fft_size//2+1, num_layers=2, n_sources=2)\n","if torch.cuda.is_available():\n","    dnn.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"200ZzzheYFD0"},"source":["np.random.seed(111)\n","idlma = GaussIDLMA(normalize='projection-back')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kK2MgFUmYGUx"},"source":["Y = idlma(X, dnn=dnn, iteration=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"m9zGVr6yYHmY"},"source":["_, y = ss.istft(Y, nperseg=fft_size, noverlap=fft_size-hop_size)\n","y = y[:,:T]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qHyWwiTLYfVe"},"source":["### 分離音"]},{"cell_type":"code","metadata":{"id":"DjZdFdZYYI_2"},"source":["for idx in range(2):\n","    display(ipd.Audio(y[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wSSliBrDYaLj"},"source":["plt.figure()\n","plt.plot(idlma.loss, color='black')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6ckQwPPZYV38"},"source":["## 3音源分離"]},{"cell_type":"code","metadata":{"id":"L4PQBrsgYWBU"},"source":["aew_mic2, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic2.wav\")\n","axb_mic2, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic2.wav\")\n","bdl_mic2, sr = sf.read(\"./data/cmu_us_bdl_arctic/trimmed/convolved-16000_deg330-mic2.wav\")\n","x_mic2 = aew_mic2 + axb_mic2 + bdl_mic2\n","\n","aew_mic4, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic4.wav\")\n","axb_mic4, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic4.wav\")\n","bdl_mic4, sr = sf.read(\"./data/cmu_us_bdl_arctic/trimmed/convolved-16000_deg330-mic4.wav\")\n","x_mic4 = aew_mic4 + axb_mic4 + bdl_mic4\n","\n","aew_mic5, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic5.wav\")\n","axb_mic5, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic5.wav\")\n","bdl_mic5, sr = sf.read(\"./data/cmu_us_bdl_arctic/trimmed/convolved-16000_deg330-mic5.wav\")\n","x_mic5 = aew_mic5 + axb_mic5 + bdl_mic5\n","\n","x = np.vstack([x_mic2, x_mic4, x_mic5])\n","n_sources, T = x.shape"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qTTIPe0YYpTO"},"source":["### インパルス応答畳み込み後の音"]},{"cell_type":"code","metadata":{"id":"1Fi4jhimYiUl"},"source":["display(ipd.Audio(aew_mic2, rate=sr))\n","display(ipd.Audio(axb_mic2, rate=sr))\n","display(ipd.Audio(bdl_mic2, rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HFD9ggWEYx35"},"source":["### 混合音"]},{"cell_type":"code","metadata":{"id":"hz92XrbLYmsz"},"source":["for idx in range(3):\n","    display(ipd.Audio(x[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXUBKhxvYsZg"},"source":["_, _, X = ss.stft(x, nperseg=fft_size, noverlap=hop_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8uUYAlpEYuIy"},"source":["### IDLMAの実行"]},{"cell_type":"code","metadata":{"id":"3VjnNkBRYtoq"},"source":["torch.manual_seed(111)\n","dnn = MLPforEstimation(n_bins=fft_size//2+1, num_layers=2, n_sources=3)\n","if torch.cuda.is_available():\n","    dnn.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hDVQbghJY095"},"source":["np.random.seed(111)\n","idlma = GaussIDLMA(normalize='projection-back')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"c62l6_01Y2Az"},"source":["Y = idlma(X, dnn=dnn, iteration=100)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XQB49XN0Y3OT"},"source":["_, y = ss.istft(Y, nperseg=fft_size, noverlap=fft_size-hop_size)\n","y = y[:,:T]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sKlAPUmGY5yx"},"source":["### 分離音"]},{"cell_type":"code","metadata":{"id":"ogtVCqKgY4Z9"},"source":["for idx in range(3):\n","    display(ipd.Audio(y[idx], rate=sr))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zj1ZTn61Y7Q6"},"source":["plt.figure()\n","plt.plot(idlma.loss, color='black')\n","plt.xlabel('Iteration')\n","plt.ylabel('Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FhP1di3xY--I"},"source":["## コールバック関数の例"]},{"cell_type":"code","metadata":{"id":"9WBaof5dY8qz"},"source":["aew_mic3, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic3.wav\")\n","axb_mic3, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic3.wav\")\n","x_mic3 = aew_mic3 + axb_mic3\n","\n","aew_mic4, sr = sf.read(\"./data/cmu_us_aew_arctic/trimmed/convolved-16000_deg60-mic4.wav\")\n","axb_mic4, sr = sf.read(\"./data/cmu_us_axb_arctic/trimmed/convolved-16000_deg300-mic4.wav\")\n","x_mic4 = aew_mic4 + axb_mic4\n","\n","x = np.vstack([x_mic3, x_mic4])\n","n_sources, T = x.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tbHAX17gY-Iz"},"source":["s = np.vstack([aew_mic3, axb_mic3])\n","_, _, X = ss.stft(x, nperseg=fft_size, noverlap=fft_size-hop_size)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"e0W-P4sYZDwk"},"source":["### SDR改善量の記録"]},{"cell_type":"code","metadata":{"id":"oKycYRcWZCUb"},"source":["%%shell\n","pip install mir_eval"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x5a3M29iZDhE"},"source":["from mir_eval.separation import bss_eval_sources\n","\n","from algorithm.projection_back import projection_back"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qGeAAIImZIHw"},"source":["def record_sdri(model):\n","    reference_id = model.reference_id\n","    s = model.target # Time domain\n","    X, Y = model.input, model.estimation # Time-frequency domain\n","    n_sources, T = s.shape\n","\n","    scale = projection_back(Y, reference=X[reference_id])\n","    Y = Y * scale[...,np.newaxis] # (n_sources, n_bins, n_frames)\n","    _, y = ss.istft(Y, nperseg=fft_size, noverlap=fft_size-hop_size)\n","    y = y[:,:T]\n","\n","    if hasattr(model, 'sdr_input'):\n","        sdr_input = model.sdr_input\n","    else:\n","        _, x = ss.istft(X, nperseg=fft_size, noverlap=fft_size-hop_size)\n","        x = x[reference_id,:T]\n","        x = np.tile(x, reps=(n_sources, 1))\n","        sdr_input, _, _, _ = bss_eval_sources(s, estimated_sources=x)\n","        model.sdr_input = sdr_input\n","\n","    sdr_estimated, _, _, _ = bss_eval_sources(s, estimated_sources=y)\n","    sdri = sdr_estimated - sdr_input\n","    \n","    model.sdri.append(sdri.mean())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hi7PdnRyZJR_"},"source":["torch.manual_seed(111)\n","dnn = MLPforEstimation(n_bins=fft_size//2+1, num_layers=2, n_sources=2)\n","if torch.cuda.is_available():\n","    dnn.cuda()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SmYkgMGvZLeY"},"source":["np.random.seed(111)\n","idlma = GaussIDLMA(normalize='projection-back', callback=record_sdri)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2w7Th0jAZMut"},"source":["Y = idlma(X, dnn=dnn, iteration=100, target=s, sdri=[])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2HS6ngQOZOPl"},"source":["plt.figure()\n","plt.plot(idlma.sdri, color='black')\n","plt.xlabel('Iteration')\n","plt.ylabel('SDR improvement')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QjD9WN7DZPYZ"},"source":[""],"execution_count":null,"outputs":[]}]}